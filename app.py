# app.py (vers√£o com Melhoria 1 e 2)

import streamlit as st
import json
import numpy as np
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer, CrossEncoder
from collections import defaultdict
import requests
import re
import unicodedata
import logging
from pathlib import Path
import zipfile
import io
import shutil
import random
from datetime import datetime
from models import get_embedding_model, get_cross_encoder_model
from concurrent.futures import ThreadPoolExecutor # <<< MELHORIA 4 ADICIONADA
from tools import (
    find_companies_by_topic,
    get_final_unified_answer,
    suggest_alternative_query,
    analyze_topic_thematically, 
    get_summary_for_topic_at_company,
    rerank_with_cross_encoder,
    rerank_by_recency,
    create_hierarchical_alias_map
    )
logger = logging.getLogger(__name__)

# --- M√≥dulos do Projeto (devem estar na mesma pasta) ---
from knowledge_base import DICIONARIO_UNIFICADO_HIERARQUICO
from analytical_engine import AnalyticalEngine

# --- Configura√ß√µes Gerais ---
st.set_page_config(page_title="Agente de An√°lise LTIP", page_icon="üîç", layout="wide", initial_sidebar_state="expanded")

MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'
TOP_K_SEARCH = 7
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
GEMINI_MODEL = "gemini-2.0-flash-lite"
CVM_SEARCH_URL = "https://www.rad.cvm.gov.br/ENET/frmConsultaExternaCVM.aspx"

FILES_TO_DOWNLOAD = {
    "item_8_4_chunks_map_final.json": "https://github.com/tovarich86/agente_bert/releases/download/dados.v3/item_8_4_chunks_map_.json",
    "item_8_4_faiss_index_final.bin": "https://github.com/tovarich86/agente_bert/releases/download/dados.v3/item_8_4_faiss_.bin",
    "outros_documentos_chunks_map_final.json": "https://github.com/tovarich86/agente_bert/releases/download/dados.v3/outros_documentos_chunks_map_.json",
    "outros_documentos_faiss_index_final.bin": "https://github.com/tovarich86/agente_bert/releases/download/dados.v3/outros_documentos_faiss_.bin",
    "resumo_fatos_e_topicos_final_enriquecido.json": "https://github.com/tovarich86/agente_bert/releases/download/dados.v3/resumo_fatos_e_topicos_final_enriquecido.json"
}
CACHE_DIR = Path("data_cache")
SUMMARY_FILENAME = "resumo_fatos_e_topicos_final_enriquecido.json"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- CARREGADOR DE DADOS ---
@st.cache_resource(show_spinner="Configurando o ambiente e baixando dados...")
def setup_and_load_data():
    CACHE_DIR.mkdir(exist_ok=True)
    
    for filename, url in FILES_TO_DOWNLOAD.items():
        local_path = CACHE_DIR / filename
        if not local_path.exists():
            logger.info(f"Baixando arquivo '{filename}'...")
            try:
                response = requests.get(url, stream=True, timeout=60)
                response.raise_for_status()
                with open(local_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                logger.info(f"'{filename}' baixado com sucesso.")
            except requests.exceptions.RequestException as e:
                st.error(f"Erro ao baixar {filename} de {url}: {e}")
                st.stop()
    # --- Carregamento de Modelos ---
    st.write("Carregando modelo de embedding...")
    embedding_model = SentenceTransformer(MODEL_NAME)
    
    st.write("Carregando modelo de Re-ranking (Cross-Encoder)...")
    cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    artifacts = {}
    for index_file in CACHE_DIR.glob('*_faiss_index_final.bin'):
        category = index_file.stem.replace('_faiss_index_final', '')
        chunks_file = CACHE_DIR / f"{category}_chunks_map_final.json"
        try:
            artifacts[category] = {
                'index': faiss.read_index(str(index_file)),
                'chunks': json.load(open(chunks_file, 'r', encoding='utf-8'))
            }
        except Exception as e:
            st.error(f"Falha ao carregar artefatos para a categoria '{category}': {e}")
            st.stop()

    summary_file_path = CACHE_DIR / SUMMARY_FILENAME
    try:
        with open(summary_file_path, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)
    except FileNotFoundError:
        st.error(f"Erro cr√≠tico: '{SUMMARY_FILENAME}' n√£o foi encontrado.")
        st.stop()

    setores = set()
    controles = set()

    for artifact_data in artifacts.values():
        chunk_map = artifact_data.get('chunks', [])
        for metadata in chunk_map:
            # Pega o valor do setor e trata se for nulo ou vazio
            setor = metadata.get('setor')
            if isinstance(setor, str) and setor.strip():
                setores.add(setor.strip().capitalize())
            else:
                setores.add("N√£o idenficado") # <-- L√ìGICA ADICIONADA

            # Pega o valor do controle e trata se for nulo ou vazio
            controle = metadata.get('controle_acionario')
            if isinstance(controle, str) and controle.strip():
                controles.add(controle.strip().capitalize())
            else:
                controles.add("N√£o identificado") # <-- L√ìGICA ADICIONADA

    # Converte os sets em listas ordenadas e adiciona "Todos" no in√≠cio
    # Garante que "N√£o Informado" n√£o seja o primeiro da lista, se existir.
    sorted_setores = sorted([s for s in setores if s != "N√£o Informado"])
    if "N√£o Informado" in setores:
        sorted_setores.append("N√£o Informado")

    sorted_controles = sorted([c for c in controles if c != "N√£o Informado"])
    if "N√£o Informado" in controles:
        sorted_controles.append("N√£o Informado")

    all_setores = ["Todos"] + sorted_setores
    all_controles = ["Todos"] + sorted_controles

    logger.info(f"Filtros din√¢micos encontrados: {len(all_setores)-1} setores e {len(all_controles)-1} tipos de controle.")

    # --- FIM DA L√ìGICA DE EXTRA√á√ÉO REFINADA ---
        
    return artifacts, summary_data, all_setores, all_controles




# --- FUN√á√ïES GLOBAIS E DE RAG ---

def _create_flat_alias_map(kb: dict) -> dict:
    alias_to_canonical = {}
    for section, topics in kb.items():
        for topic_name_raw, aliases in topics.items():
            canonical_name = topic_name_raw.replace('_', ' ')
            alias_to_canonical[canonical_name.lower()] = canonical_name
            for alias in aliases:
                alias_to_canonical[alias.lower()] = canonical_name
    return alias_to_canonical

AVAILABLE_TOPICS = list(set(_create_flat_alias_map(DICIONARIO_UNIFICADO_HIERARQUICO).values()))

def expand_search_terms(base_term: str, kb: dict) -> list[str]:
    base_term_lower = base_term.lower()
    expanded_terms = {base_term_lower}
    for section, topics in kb.items():
        for topic, aliases in topics.items():
            all_terms_in_group = {alias.lower() for alias in aliases} | {topic.lower().replace('_', ' ')}
            if base_term_lower in all_terms_in_group:
                expanded_terms.update(all_terms_in_group)
    return list(expanded_terms)

# Em app.py, substitua esta fun√ß√£o
def search_by_tags(chunks_to_search: list[dict], target_tags: list[str]) -> list[dict]:
    """Busca chunks que contenham tags de t√≥picos espec√≠ficos."""
    results = []
    target_tags_lower = {tag.lower() for tag in target_tags}

    for i, chunk_info in enumerate(chunks_to_search):
        chunk_text = chunk_info.get("text", "")
        found_topics_in_chunk = re.findall(r'\[topico:([^\]]+)\]', chunk_text)

        if found_topics_in_chunk:
            # O t√≥pico pode ser uma lista, ex: [topico:Vesting,Aceleracao]
            topics_in_chunk_set = {t.strip().lower() for t in found_topics_in_chunk[0].split(',')}

            # Se houver qualquer sobreposi√ß√£o entre as tags procuradas e as encontradas
            if not target_tags_lower.isdisjoint(topics_in_chunk_set):
                results.append(chunk_info)
    return results

def get_final_unified_answer(query: str, context: str) -> str:
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    has_complete_8_4 = "formul√°rio de refer√™ncia" in query.lower() and "8.4" in query.lower()
    has_tagged_chunks = "--- CONTE√öDO RELEVANTE" in context
    structure_instruction = "Organize a resposta de forma l√≥gica e clara usando Markdown."
    if has_complete_8_4:
        structure_instruction = "ESTRUTURA OBRIGAT√ìRIA PARA ITEM 8.4: Use a estrutura oficial do item 8.4 do Formul√°rio de Refer√™ncia (a, b, c...)."
    elif has_tagged_chunks:
        structure_instruction = "PRIORIZE as informa√ß√µes dos chunks recuperados e organize a resposta de forma l√≥gica."
    prompt = f"""Voc√™ √© um consultor especialista em planos de incentivo de longo prazo (ILP).
    PERGUNTA ORIGINAL DO USU√ÅRIO: "{query}"
    CONTEXTO COLETADO DOS DOCUMENTOS:
    {context}
    {structure_instruction}
    INSTRU√á√ïES PARA O RELAT√ìRIO FINAL:
    1. Responda diretamente √† pergunta do usu√°rio com base no contexto fornecido.
    2. Seja detalhado, preciso e profissional na sua linguagem. Use formata√ß√£o Markdown.
    3. Se uma informa√ß√£o espec√≠fica pedida n√£o estiver no contexto, declare explicitamente: "Informa√ß√£o n√£o encontrada nas fontes analisadas.". N√£o invente dados.
    RELAT√ìRIO ANAL√çTICO FINAL:"""
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {'Content-Type': 'application/json'}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=180)
        response.raise_for_status()
        return response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
    except Exception as e:
        logger.error(f"ERRO ao gerar resposta final com LLM: {e}")
        return f"Ocorreu um erro ao contatar o modelo de linguagem. Detalhes: {str(e)}"

# <<< MELHORIA 1 ADICIONADA >>>
def get_query_intent_with_llm(query: str) -> str:
    """
    Usa um LLM para classificar a inten√ß√£o do usu√°rio em 'quantitativa' ou 'qualitativa'.
    Retorna 'qualitativa' como padr√£o em caso de erro.
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    
    prompt = f"""
    Analise a pergunta do usu√°rio e classifique a sua inten√ß√£o principal. Responda APENAS com uma √∫nica palavra em JSON.
    
    As op√ß√µes de classifica√ß√£o s√£o:
    1. "quantitativa": Se a pergunta busca por n√∫meros, listas diretas, contagens, m√©dias, estat√≠sticas ou agrega√ß√µes. 
       Exemplos: "Quantas empresas t√™m TSR Relativo?", "Qual a m√©dia de vesting?", "Liste as empresas com desconto no strike.".
    2. "qualitativa": Se a pergunta busca por explica√ß√µes, detalhes, compara√ß√µes, descri√ß√µes ou an√°lises aprofundadas.
       Exemplos: "Como funciona o plano da Vale?", "Compare os planos da Hypera e Movida.", "Detalhe o tratamento de dividendos.".

    Pergunta do Usu√°rio: "{query}"

    Responda apenas com o JSON da classifica√ß√£o. Exemplo de resposta: {{"intent": "qualitativa"}}
    """
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.0,
            "maxOutputTokens": 50
        }
    }
    headers = {'Content-Type': 'application/json'}

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
        response.raise_for_status()
        
        response_text = response.json()['candidates'][0]['content']['parts'][0]['text']
        intent_json = json.loads(re.search(r'\{.*\}', response_text, re.DOTALL).group())
        intent = intent_json.get("intent", "qualitativa").lower()
        
        logger.info(f"Inten√ß√£o detectada pelo LLM: '{intent}' para a pergunta: '{query}'")
        
        if intent in ["quantitativa", "qualitativa"]:
            return intent
        else:
            logger.warning(f"Inten√ß√£o n√£o reconhecida '{intent}'. Usando 'qualitativa' como padr√£o.")
            return "qualitativa"

    except Exception as e:
        logger.error(f"ERRO ao determinar inten√ß√£o com LLM: {e}. Usando 'qualitativa' como padr√£o.")
        return "qualitativa"

# <<< MELHORIA 2 APLICADA >>>
# Fun√ß√£o modificada para lidar com buscas gerais (sem empresa)
# Em app.py, substitua esta fun√ß√£o
def execute_dynamic_plan(
    query: str,
    plan: dict,
    artifacts: dict,
    model: SentenceTransformer,
    cross_encoder_model: CrossEncoder,
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,
    # Fun√ß√µes auxiliares como depend√™ncias expl√≠citas
    search_by_tags: callable,
    expand_search_terms: callable,
    prioritize_recency: bool = True,
) -> tuple[str, list[dict]]:
    """
    Vers√£o 4.0 (Definitiva e Completa) do Executor de Planos.
    """
    logger.info(f"Executando plano v4.0 (Definitivo) para query: '{query}'")
    
    # --- PONTO DE DEBUG SEGURO ---
    debug_info = {}
    
    # Passo 1: Coletar todos os chunks em uma √∫nica lista.
    all_chunks = []
    for artifact_name, artifact_data in artifacts.items():
        list_of_chunks = artifact_data.get('chunks', [])
        if isinstance(list_of_chunks, list):
            for chunk in list_of_chunks:
                # --- ADICIONE ESTA LINHA ---
                # Renomeia 'chunk_text' para 'text' para compatibilidade.
                if 'chunk_text' in chunk:
                    chunk['text'] = chunk.pop('chunk_text')
                # -------------------------
                chunk['doc_type'] = artifact_name
            all_chunks.extend(list_of_chunks)

    debug_info["Total de Chunks Carregados (Antes dos filtros)"] = len(all_chunks)

    # Passo 2: Aplicar filtros.
    filtros = plan.get("filtros", {}) # Acessa os filtros do plano
    pre_filtered_chunks = all_chunks
    if filtros.get('setor'):
        pre_filtered_chunks = [c for c in pre_filtered_chunks if c.get('setor', '').lower() == filtros['setor'].lower()]
    debug_info["Chunks Restantes (Ap√≥s filtro de Setor)"] = len(pre_filtered_chunks)

    if filtros.get('controle_acionario'):
        pre_filtered_chunks = [c for c in pre_filtered_chunks if c.get('controle_acionario', '').lower() == filtros['controle_acionario'].lower()]
    debug_info["Chunks Restantes (Ap√≥s filtro de Controle)"] = len(pre_filtered_chunks)

    with st.expander("üïµÔ∏è DEBUG: Rastreamento do Carregamento de Documentos (Chunks)"):
        st.json(debug_info)
    # --- FIM DO DEBUG ---

    logger.info(f"Ap√≥s pr√©-filtragem por metadados, {len(pre_filtered_chunks)} chunks s√£o candidatos iniciais.")

    # --- EST√ÅGIO 0: CONFIGURA√á√ÉO E FUN√á√ïES AUXILIARES ---
     
    candidate_chunks_dict = {}
    TOP_K_INITIAL_RETRIEVAL = 30
    TOP_K_FINAL = 10

    plan_type = plan.get("plan_type", "default")
    empresas = plan.get("empresas", [])
    topicos = plan.get("topicos", [])
    filtros = plan.get("filtros", {})

    def _is_company_match(plan_canonical_name: str, metadata_name: str) -> bool:
        if not plan_canonical_name or not metadata_name: return False
        chunk_canonical_name = company_lookup_map.get(metadata_name.lower())
        if chunk_canonical_name and chunk_canonical_name.lower() == plan_canonical_name.lower():
            return True
        searchable_part = unicodedata.normalize('NFKD', plan_canonical_name.lower()).encode('ascii', 'ignore').decode('utf-8').split(' ')[0]
        return searchable_part in metadata_name.lower()

    def add_candidate(chunk_info: dict):
        chunk_hash = hash(chunk_info.get("text", ""))
        if chunk_hash not in candidate_chunks_dict:
            candidate_chunks_dict[chunk_hash] = chunk_info

    # --- EST√ÅGIO 1: PR√â-FILTRAGEM GLOBAL ---
        all_chunks = []
        for artifact_name, artifact_data in artifacts.items():
            list_of_chunks = artifact_data.get('chunks', [])

            if not isinstance(list_of_chunks, list):
                logger.warning(f"Formato inesperado para chunks em '{artifact_name}'. Esperava uma lista.")
                continue

            for chunk_meta in list_of_chunks:
                # Renomeia a chave de texto para garantir a compatibilidade.
                if 'chunk_text' in chunk_meta and 'text' not in chunk_meta:
                    chunk_meta['text'] = chunk_meta.pop('chunk_text')
            
                chunk_meta['doc_type'] = artifact_name
                all_chunks.append(chunk_meta)

        # Passo 2: Aplicar filtros sobre a lista j√° populada.
        # Esta abordagem sequencial elimina o UnboundLocalError.
        pre_filtered_chunks = all_chunks
        if filtros.get('setor'):
            pre_filtered_chunks = [c for c in pre_filtered_chunks if c.get('setor', '').lower() == filtros['setor'].lower()]

        if filtros.get('controle_acionario'):
            pre_filtered_chunks = [c for c in pre_filtered_chunks if c.get('controle_acionario', '').lower() == filtros['controle_acionario'].lower()]

        logger.info(f"Ap√≥s pr√©-filtragem por metadados, {len(pre_filtered_chunks)} chunks s√£o candidatos iniciais.")

    # --- EST√ÅGIO 2: ROTEAMENTO E BUSCA H√çBRIDA DETALHADA ---
    
    # ROTA 1: Plano especial para buscar o Item 8.4
    if plan_type == "section_8_4" and empresas:
        canonical_name_from_plan = empresas[0]
        search_name = next((e.get("search_alias", canonical_name_from_plan) for e in company_catalog_rich if e.get("canonical_name") == canonical_name_from_plan), canonical_name_from_plan)
        logger.info(f"ROTA section_8_4: Usando nome de busca '{search_name}' para '{canonical_name_from_plan}'")
        
        # Filtra ainda mais os chunks para o documento e empresa espec√≠ficos
        chunks_to_search = [c for c in pre_filtered_chunks if c.get('doc_type') == 'item_8_4' and _is_company_match(canonical_name_from_plan, c.get('company_name', ''))]
        if chunks_to_search:
            # Constr√≥i um √≠ndice FAISS tempor√°rio para esta busca espec√≠fica e otimizada
            temp_embeddings = model.encode([c['text'] for c in chunks_to_search], normalize_embeddings=True).astype('float32')
            temp_index = faiss.IndexFlatIP(temp_embeddings.shape[1])
            temp_index.add(temp_embeddings)
              # --- IN√çCIO DA L√ìGICA OTIMIZADA ---
        
            # Etapa 2: Preparar TODAS as queries de busca primeiro
            all_search_queries = []
            for topico in topicos:
                for term in expand_search_terms(topico, kb)[:3]: # Pega at√© 3 expans√µes por t√≥pico
                    all_search_queries.append(f"explica√ß√£o detalhada sobre o conceito e funcionamento de {term}")

            if not all_search_queries:
                 logger.warning("Nenhuma query de busca foi gerada a partir dos t√≥picos.")
                 return "N√£o encontrei informa√ß√µes relevantes para esta combina√ß√£o.", []
        
            logger.info(f"Codificando {len(all_search_queries)} varia√ß√µes de busca em lote...")
        
            # Etapa 3: Codificar TODAS as queries de uma s√≥ vez (muito mais r√°pido)
            query_embeddings = model.encode(all_search_queries, normalize_embeddings=True).astype('float32')
        
            # Etapa 4: Executar a busca para todas as queries de uma vez
            # k_per_query ajusta quantos resultados buscar por cada varia√ß√£o da query
            k_per_query = max(1, TOP_K_FINAL // len(all_search_queries))
            _, all_indices = temp_index.search(query_embeddings, k_per_query)
        
            # Etapa 5: Coletar todos os resultados √∫nicos
            for indices_row in all_indices:
                for idx in indices_row:
                    if idx != -1:
                        add_candidate(chunks_to_search[idx])
        # --- FIM DA L√ìGICA OTIMIZADA ---
    # ROTA 2: Planos Padr√£o (Default, Summary)
    else:
        # CASO 2.1: Busca geral por t√≥pico (sem empresa)
        if not empresas and topicos:
            logger.info(f"ROTA Default (Geral): Executando busca conceitual para os t√≥picos: {topicos}")
                    # --- OTIMIZA√á√ÉO AQUI ---
            sample_size = 100 # Pega uma amostra de 4000 chunks para a busca geral
            if len(pre_filtered_chunks) > sample_size:
                logger.info(f"Base de chunks grande ({len(pre_filtered_chunks)}). Usando uma amostra de {sample_size} para a busca geral.")
                chunks_to_search = random.sample(pre_filtered_chunks, sample_size)
            else:
                chunks_to_search = pre_filtered_chunks
        # --- FIM DA OTIMIZA√á√ÉO ---
            # Constr√≥i √≠ndice FAISS tempor√°rio com todos os chunks pr√©-filtrados
            temp_embeddings = model.encode([c['text'] for c in chunks_to_search], normalize_embeddings=True).astype('float32')
            temp_index = faiss.IndexFlatIP(temp_embeddings.shape[1])
            temp_index.add(temp_embeddings)
            
            for topico in topicos:
                for term in expand_search_terms(topico, kb)[:3]:
                    search_query = f"explica√ß√£o detalhada sobre o conceito e funcionamento de {term}"
                    query_embedding = model.encode([search_query], normalize_embeddings=True).astype('float32')
                    _, indices = temp_index.search(query_embedding, TOP_K_FINAL)
                    for idx in indices[0]:
                        if idx != -1: add_candidate(pre_filtered_chunks[idx])

        # CASO 2.2: Busca por empresa e t√≥picos (incluindo resumos) - A MAIS COMPLETA
        # CASO 2.2: Busca por empresa e t√≥picos (incluindo resumos) - A MAIS COMPLETA
        # CASO 2.2: Busca por empresa e t√≥picos (incluindo resumos) - A MAIS COMPLETA
        elif empresas and topicos:
            logger.info(f"ROTA Default (H√≠brida): Executando busca para Empresas: {empresas} e T√≥picos: {topicos}")

          # --- CORRE√á√ÉO FUNDAMENTAL: FILTRAR CHUNKS POR EMPRESA PRIMEIRO ---
          # Cria um subconjunto de chunks contendo APENAS as empresas solicitadas no plano.
             strictly_filtered_chunks = []
            for empresa_canonica in empresas:
              chunks_for_this_company = [
                    c for c in pre_filtered_chunks if _is_company_match(empresa_canonica, c.get('company_name', ''))
                ]
              
              # L√≥gica de deduplica√ß√£o/rec√™ncia (bom para manter a qualidade)
                docs_by_url = defaultdict(list)
                for chunk in chunks_for_this_company:
                  docs_by_url[chunk.get('source_url')].append(chunk)

                MAX_DOCS_PER_COMPANY = 3 # Limita a 3 documentos por empresa
                if len(docs_by_url) > MAX_DOCS_PER_COMPANY:
                    def get_sort_key(url):
                        match = re.search(r'(?:NumeroProtocoloEntrega=|rada-cvm/|/id/)\d{4,}(\d+)', str(url))
                        return int(match.group(1)) if match else 0
                    sorted_urls = sorted(docs_by_url.keys(), key=get_sort_key, reverse=True)
                    latest_urls = sorted_urls[:MAX_DOCS_PER_COMPANY]
                  
                    for url in latest_urls:
                        strictly_filtered_chunks.extend(docs_by_url[url])
                else:
                    strictly_filtered_chunks.extend(chunks_for_this_company)

            logger.info(f"Busca focada em {len(strictly_filtered_chunks)} chunks das {len(empresas)} empresas solicitadas.")
          
            if not strictly_filtered_chunks:
                logger.warning(f"Nenhum chunk encontrado para as empresas {empresas} ap√≥s a filtragem.")
            else:
                # Parte 1: Busca por Tags (na lista j√° filtrada)
                target_tags = set().union(*(expand_search_terms(t, kb) for t in topicos))
                tagged_chunks = search_by_tags(strictly_filtered_chunks, list(target_tags))
                for chunk_info in tagged_chunks:
                    add_candidate(chunk_info)
              
                # Parte 2: Busca Vetorial (no conjunto min√∫sculo e estritamente filtrado)
                temp_embeddings = model.encode([c['text'] for c in strictly_filtered_chunks], normalize_embeddings=True, batch_size=32).astype('float32')
                temp_index = faiss.IndexFlatIP(temp_embeddings.shape[1])
                temp_index.add(temp_embeddings)
              
                for empresa_canonica in empresas:
                    search_name = next((e.get("search_alias", empresa_canonica) for e in company_catalog_rich if e.get("canonical_name") == empresa_canonica), empresa_canonica)
                    for topico in topicos:
                        search_query = f"informa√ß√µes detalhadas sobre {topico} no plano da empresa {search_name}"
                        query_embedding = model.encode([search_query], normalize_embeddings=True).astype('float32')
                        _, indices = temp_index.search(query_embedding, min(TOP_K_INITIAL_RETRIEVAL, len(strictly_filtered_chunks)))
                        for idx in indices[0]:
                            if idx != -1:
                                add_candidate(strictly_filtered_chunks[idx])

   

    # --- EST√ÅGIO 3: RE-RANKING FINAL ---
    if not candidate_chunks_dict:
        logger.warning(f"Nenhum chunk candidato encontrado para a query: '{query}' com os filtros aplicados.")
        return "N√£o encontrei informa√ß√µes relevantes para esta combina√ß√£o espec√≠fica de consulta e filtros.", []
    
    candidate_list = list(candidate_chunks_dict.values())
    logger.info(f"Total de {len(candidate_list)} chunks candidatos √∫nicos encontrados. Re-ranqueando...")
    
    reranked_chunks = rerank_with_cross_encoder(query, candidate_list, cross_encoder_model, top_n=TOP_K_FINAL)
    
    # Constru√ß√£o do Contexto Final
    full_context = ""
    retrieved_sources = []
    seen_sources = set()

    for chunk in reranked_chunks:
        company_name = chunk.get('company_name', 'N/A')
        source_url = chunk.get('source_url', 'N/A')
        
        source_header = f"(Empresa: {company_name}, Setor: {chunk.get('setor', 'N/A')}, Documento: {chunk.get('doc_type', 'N/A')})"
        clean_text = re.sub(r'\[.*?\]', '', chunk.get('text', '')).strip()
        full_context += f"--- CONTE√öDO RELEVANTE {source_header} ---\n{clean_text}\n\n"
        
        source_tuple = (company_name, source_url)
        if source_tuple not in seen_sources:
            seen_sources.add(source_tuple)
            retrieved_sources.append(chunk)
            
    logger.info(f"Contexto final constru√≠do a partir de {len(reranked_chunks)} chunks re-ranqueados.")
    return full_context, retrieved_sources
    
def create_dynamic_analysis_plan(query, company_catalog_rich, kb, summary_data, filters: dict):
    """
    Vers√£o 3.0 (Unificada) do planejador din√¢mico.

    Esta vers√£o combina o melhor de ambas as propostas:
    1.  EXTRAI filtros de metadados (setor, controle acion√°rio).
    2.  EXTRAI t√≥picos hier√°rquicos completos.
    3.  RESTAURA a detec√ß√£o de inten√ß√£o de "Resumo Geral" para perguntas abertas.
    4.  MANT√âM a detec√ß√£o da inten√ß√£o especial "Item 8.4".
    """
    logger.info(f"Gerando plano din√¢mico v3.0 para a pergunta: '{query}'")
    query_lower = query.lower().strip()
    
    plan = {
        "empresas": [],
        "topicos": [],
        "filtros": filters.copy(),
        "plan_type": "default" # O tipo de plano default aciona a busca RAG padr√£o.
    }



    # --- PASSO 2: Identifica√ß√£o Robusta de Empresas (L√≥gica Original Mantida) ---
    mentioned_companies = []
    if company_catalog_rich:
        companies_found_by_alias = {}
        for company_data in company_catalog_rich:
            canonical_name = company_data.get("canonical_name")
            if not canonical_name: continue
            
            all_aliases = company_data.get("aliases", []) + [canonical_name]
            for alias in all_aliases:
                if re.search(r'\b' + re.escape(alias.lower()) + r'\b', query_lower):
                    score = len(alias.split())
                    if canonical_name not in companies_found_by_alias or score > companies_found_by_alias[canonical_name]:
                        companies_found_by_alias[canonical_name] = score
        if companies_found_by_alias:
            mentioned_companies = [c for c, s in sorted(companies_found_by_alias.items(), key=lambda item: item[1], reverse=True)]

    if not mentioned_companies:
        for empresa_nome in summary_data.keys():
            if re.search(r'\b' + re.escape(empresa_nome.lower()) + r'\b', query_lower):
                mentioned_companies.append(empresa_nome)
    
    plan["empresas"] = mentioned_companies
    logger.info(f"Empresas identificadas: {plan['empresas']}")

    # --- PASSO 3: Detec√ß√£o de Inten√ß√µes Especiais (L√ìGICA UNIFICADA) ---
    # Palavras-chave para as inten√ß√µes especiais
    summary_keywords = ['resumo geral', 'plano completo', 'como funciona o plano', 'descreva o plano', 'resumo do plano', 'detalhes do plano']
    section_8_4_keywords = ['item 8.4', 'se√ß√£o 8.4', '8.4 do fre']
    
    is_summary_request = any(keyword in query_lower for keyword in summary_keywords)
    is_section_8_4_request = any(keyword in query_lower for keyword in section_8_4_keywords)

    if plan["empresas"] and is_section_8_4_request:
        plan["plan_type"] = "section_8_4"
        # O t√≥pico √© o caminho hier√°rquico para a se√ß√£o inteira
        plan["topicos"] = ["FormularioReferencia,Item_8_4"]
        logger.info("Plano especial 'section_8_4' detectado.")
        return {"status": "success", "plan": plan}
    
    # [L√ìGICA RESTAURADA E ADAPTADA]
    # Se for uma pergunta de resumo para uma empresa, define um conjunto de t√≥picos essenciais.
    elif plan["empresas"] and is_summary_request:
        plan["plan_type"] = "summary" # Um tipo especial para indicar um resumo completo
        logger.info("Plano especial 'summary' detectado. Montando plano com t√≥picos essenciais.")
        # Define os CAMINHOS HIER√ÅRQUICOS essenciais para um bom resumo.
        plan["topicos"] = [
            "TiposDePlano",
            "ParticipantesCondicoes,Elegibilidade",
            "Mecanicas,Vesting",
            "Mecanicas,Lockup",
            "IndicadoresPerformance",
            "GovernancaRisco,MalusClawback",
            "EventosFinanceiros,DividendosProventos"
        ]
        return {"status": "success", "plan": plan}

    # --- PASSO 4: Extra√ß√£o de T√≥picos Hier√°rquicos (Se Nenhuma Inten√ß√£o Especial Foi Ativada) ---
    alias_map = create_hierarchical_alias_map(kb)
    with st.expander("üïµÔ∏è DEBUG: Conte√∫do do Dicion√°rio de Busca (Alias Map)"):
        st.json(alias_map)
    found_topics = set()
    
    # Ordena os aliases por comprimento para encontrar o mais espec√≠fico primeiro
    for alias in sorted(alias_map.keys(), key=len, reverse=True):
        # Usamos uma regex mais estrita para evitar matches parciais (ex: 'TSR' em 'TSR Relativo')
        if re.search(r'\b' + re.escape(alias) + r'\b', query_lower):
            found_topics.add(alias_map[alias])
    
    plan["topicos"] = sorted(list(found_topics))
    if plan["topicos"]:
        logger.info(f"Caminhos de t√≥picos identificados: {plan['topicos']}")
    if plan["empresas"] and not plan["topicos"]:
        logger.info("Nenhum t√≥pico espec√≠fico encontrado. Ativando modo de resumo/compara√ß√£o geral.")
        plan["plan_type"] = "summary"
        # Define os CAMINHOS HIER√ÅRQUICOS essenciais para um bom resumo/compara√ß√£o.
        plan["topicos"] = [
            "TiposDePlano",
            "ParticipantesCondicoes,Elegibilidade",
            "MecanicasCicloDeVida,Vesting",
            "MecanicasCicloDeVida,Lockup",
            "IndicadoresPerformance",
            "GovernancaRisco,MalusClawback",
            "EventosFinanceiros,DividendosProventos"
        ]
        logger.info(f"T√≥picos de resumo geral adicionados ao plano: {plan['topicos']}")    

    # --- PASSO 5: Valida√ß√£o Final ---
    if not plan["empresas"] and not plan["topicos"] and not plan["filtros"]:
        logger.warning("Planejador n√£o conseguiu identificar empresa, t√≥pico ou filtro na pergunta.")
        return {"status": "error", "message": "N√£o foi poss√≠vel identificar uma inten√ß√£o clara na sua pergunta. Tente ser mais espec√≠fico."}
        
    return {"status": "success", "plan": plan}

    
def analyze_single_company(
    empresa: str,
    plan: dict,
    query: str,
    artifacts: dict,
    model: SentenceTransformer,
    cross_encoder_model: CrossEncoder,
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,
    execute_dynamic_plan_func: callable,
    get_final_unified_answer_func: callable
) -> dict:
    """
    Executa o plano de an√°lise para uma √∫nica empresa e retorna um dicion√°rio estruturado.
    Esta fun√ß√£o √© projetada para ser executada em um processo paralelo.
    """
    single_plan = {'empresas': [empresa], 'topicos': plan['topicos']}
    
    # --- CORRE√á√ÉO APLICADA AQUI ---
    # Adicionado o argumento 'is_summary_plan=False' na chamada.
    context, sources_list = execute_dynamic_plan_func(query, single_plan, artifacts, model, cross_encoder_model, kb, company_catalog_rich,
        company_lookup_map, search_by_tags, expand_search_terms)
    
    result_data = {
        "empresa": empresa,
        "resumos_por_topico": {topico: "Informa√ß√£o n√£o encontrada" for topico in plan['topicos']},
        "sources": sources_list
    }

    if context:
        summary_prompt = f"""
        Com base no CONTEXTO abaixo sobre a empresa {empresa}, crie um resumo para cada um dos T√ìPICOS solicitados.
        Sua resposta deve ser APENAS um objeto JSON v√°lido, sem nenhum texto adicional antes ou depois.
        
        T√ìPICOS PARA RESUMIR: {json.dumps(plan['topicos'])}
        
        CONTEXTO:
        {context}
        
        FORMATO OBRIGAT√ìRIO DA RESPOSTA (APENAS JSON):
        {{
          "resumos_por_topico": {{
            "T√≥pico 1": "Resumo conciso sobre o T√≥pico 1...",
            "T√≥pico 2": "Resumo conciso sobre o T√≥pico 2...",
            "...": "..."
          }}
        }}
        """
        
        try:
            json_response_str = get_final_unified_answer_func(summary_prompt, context)
            json_match = re.search(r'\{.*\}', json_response_str, re.DOTALL)
            if json_match:
                parsed_json = json.loads(json_match.group())
                result_data["resumos_por_topico"] = parsed_json.get("resumos_por_topico", result_data["resumos_por_topico"])
            else:
                logger.warning(f"N√£o foi poss√≠vel extrair JSON da resposta para a empresa {empresa}.")

        except (json.JSONDecodeError, Exception) as e:
            logger.error(f"Erro ao processar o resumo JSON para {empresa}: {e}")
            
    return result_data


def handle_rag_query(
    query: str,
    artifacts: dict,
    embedding_model: SentenceTransformer,
    cross_encoder_model: CrossEncoder,
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,  # <-- ESTE √â O PAR√ÇMETRO QUE FALTAVA
    summary_data: dict,
    filters: dict,
    prioritize_recency: bool = True
) -> tuple[str, list[dict]]:
    """
    Orquestra o pipeline de RAG para perguntas qualitativas, incluindo a gera√ß√£o do plano,
    a execu√ß√£o da busca (com re-ranking) e a s√≠ntese da resposta final.
    """
    with st.status("1Ô∏è‚É£ Gerando plano de an√°lise...", expanded=True) as status:
        plan_response = create_dynamic_analysis_plan(query, company_catalog_rich, kb, summary_data, filters)
        
        if plan_response['status'] != "success":
            status.update(label="‚ö†Ô∏è Falha na identifica√ß√£o", state="error", expanded=True)
            
            st.warning("N√£o consegui identificar uma empresa conhecida na sua pergunta para realizar uma an√°lise profunda.")
            st.info("Para an√°lises detalhadas, por favor, use o nome de uma das empresas listadas na barra lateral.")
            
            with st.spinner("Estou pensando em uma pergunta alternativa que eu possa responder..."):
                alternative_query = suggest_alternative_query(query, kb) # Passe o kb
            
            st.markdown("#### Que tal tentar uma pergunta mais geral?")
            st.markdown("Voc√™ pode copiar a sugest√£o abaixo ou reformular sua pergunta original.")
            st.code(alternative_query, language=None)
            
            # Retornamos uma string vazia para o texto e para as fontes, encerrando a an√°lise de forma limpa.
            return "", []
        # --- FIM DO NOVO BLOCO ---
            
        plan = plan_response['plan']
        
        summary_keywords = ['resumo', 'geral', 'completo', 'vis√£o geral', 'como funciona o plano', 'detalhes do plano']
        is_summary_request = any(keyword in query.lower() for keyword in summary_keywords)
        
        specific_topics_in_query = list({canonical for alias, canonical in _create_flat_alias_map(kb).items() if re.search(r'\b' + re.escape(alias) + r'\b', query.lower())})
        is_summary_plan = is_summary_request and not specific_topics_in_query
        
        if plan['empresas']:
            st.write(f"**üè¢ Empresas identificadas:** {', '.join(plan['empresas'])}")
        else:
            st.write("**üè¢ Nenhuma empresa espec√≠fica identificada. Realizando busca geral.**")
            
        st.write(f"**üìù T√≥picos a analisar:** {', '.join(plan['topicos'])}")
        if is_summary_plan:
            st.info("üí° Modo de resumo geral ativado. A busca ser√° otimizada para os t√≥picos encontrados.")
            
        status.update(label="‚úÖ Plano gerado com sucesso!", state="complete")

    final_answer, all_sources_structured = "", []
    seen_sources_tuples = set()

    # --- L√≥gica para M√∫ltiplas Empresas (Compara√ß√£o) ---
    if len(plan.get('empresas', [])) > 1:
        st.info(f"Modo de compara√ß√£o ativado para {len(plan['empresas'])} empresas. Executando an√°lises em paralelo...")
        
        with st.spinner(f"Analisando {len(plan['empresas'])} empresas..."):
            with ThreadPoolExecutor(max_workers=len(plan['empresas'])) as executor:
                futures = [
                    executor.submit(
                        analyze_single_company, empresa, plan, query, artifacts, embedding_model, cross_encoder_model, 
                        kb, company_catalog_rich, company_lookup_map, execute_dynamic_plan, get_final_unified_answer) 
                    for empresa in plan['empresas']
                ]
                results = [future.result() for future in futures]

        for result in results:
            for src_dict in result.get('sources', []):
                company_name = src_dict.get('company_name')
                source_url = src_dict.get('source_url')
                
                if company_name and source_url:
                    src_tuple = (company_name, source_url)
                    if src_tuple not in seen_sources_tuples:
                        seen_sources_tuples.add(src_tuple)
                        all_sources_structured.append(src_dict)

        with st.status("Gerando relat√≥rio comparativo final...", expanded=True) as status:
            clean_results = []
            for company_result in results:
                # Remove a chave 'sources' temporariamente para limpeza
                sources = company_result.pop("sources", [])
                clean_sources = []
                for source_chunk in sources:
                    # Remove a chave 'relevance_score' de cada chunk
                    source_chunk.pop('relevance_score', None)
                    clean_sources.append(source_chunk)
                
                # Adiciona as fontes limpas de volta
                company_result["sources"] = clean_sources
                clean_results.append(company_result)
            structured_context = json.dumps(results, indent=2, ensure_ascii=False)
            comparison_prompt = f"""
            Sua tarefa √© criar um relat√≥rio comparativo detalhado sobre "{query}".
            Use os dados estruturados fornecidos no CONTEXTO JSON abaixo.
            O relat√≥rio deve come√ßar com uma breve an√°lise textual e, em seguida, apresentar uma TABELA MARKDOWN clara e bem formatada.

            CONTEXTO (em formato JSON):
            {structured_context}
            """
            final_answer = get_final_unified_answer(comparison_prompt, structured_context)
            status.update(label="‚úÖ Relat√≥rio comparativo gerado!", state="complete")
            
    # --- L√≥gica para Empresa √önica ou Busca Geral ---
    else:
        with st.status("2Ô∏è‚É£ Recuperando e re-ranqueando contexto...", expanded=True) as status:
            context, all_sources_structured = execute_dynamic_plan(
                query, plan, artifacts, embedding_model, cross_encoder_model, kb,company_catalog_rich, company_lookup_map, search_by_tags, expand_search_terms,prioritize_recency=prioritize_recency)
            
            if not context:
                st.error("‚ùå N√£o encontrei informa√ß√µes relevantes nos documentos para a sua consulta.")
                return "Nenhuma informa√ß√£o relevante encontrada.", []
                
            st.write(f"**üìÑ Contexto recuperado de:** {len(all_sources_structured)} documento(s)")
            status.update(label="‚úÖ Contexto relevante selecionado!", state="complete")
        
        with st.status("3Ô∏è‚É£ Gerando resposta final...", expanded=True) as status:
            final_answer = get_final_unified_answer(query, context)
            status.update(label="‚úÖ An√°lise conclu√≠da!", state="complete")

    return final_answer, all_sources_structured

def main():
    st.title("ü§ñ Agente de An√°lise de Planos de Incentivo (ILP)")
    st.markdown("---")

    embedding_model = get_embedding_model()
    cross_encoder_model = get_cross_encoder_model()

    # 2. Carregue os dados (a fun√ß√£o agora s√≥ retorna 4 valores)
    artifacts, summary_data, setores_disponiveis, controles_disponiveis = setup_and_load_data()
        
    if not summary_data or not artifacts:
        st.error("‚ùå Falha cr√≠tica no carregamento dos dados. O app n√£o pode continuar.")
        st.stop()
    
    engine = AnalyticalEngine(summary_data, DICIONARIO_UNIFICADO_HIERARQUICO) 
    
    try:
        from catalog_data import company_catalog_rich 
    except ImportError:
        company_catalog_rich = [] 
    
    st.session_state.company_catalog_rich = company_catalog_rich

   
    from tools import _create_company_lookup_map
    st.session_state.company_lookup_map = _create_company_lookup_map(company_catalog_rich)


    with st.sidebar:
        st.header("üìä Informa√ß√µes do Sistema")
        st.metric("Categorias de Documentos (RAG)", len(artifacts))
        st.metric("Empresas no Resumo", len(summary_data))
                # --- MODIFICA√á√ÉO 2: Usar as listas din√¢micas ---
        st.header("‚öôÔ∏è Filtros da An√°lise")
        st.caption("Filtre a base de dados antes de fazer sua pergunta.")
        
        selected_setor = st.selectbox(
            label="Filtrar por Setor",
            options=setores_disponiveis, # Usa a lista din√¢mica
            index=0
        )
        
        selected_controle = st.selectbox(
            label="Filtrar por Controle Acion√°rio",
            options=controles_disponiveis, # Usa a lista din√¢mica
            index=0
        )
     


        # Checkbox para ativar/desativar o re-ranking por rec√™ncia
        prioritize_recency = st.checkbox(
        "Priorizar documentos mais recentes", 
        value=True, # Ligado por padr√£o, pois √© uma feature poderosa
        help="D√° um b√¥nus de relev√¢ncia para os documentos mais novos, fazendo com que apare√ßam primeiro nos resultados."
        )
        st.markdown("---") 
        with st.expander("Empresas com dados no resumo"):
            st.dataframe(pd.DataFrame(sorted(list(summary_data.keys())), columns=["Empresa"]), use_container_width=True, hide_index=True)
        st.success("‚úÖ Sistema pronto para an√°lise")
        st.info(f"Embedding Model: `{MODEL_NAME}`")
        st.info(f"Generative Model: `{GEMINI_MODEL}`")
    
    st.header("üí¨ Fa√ßa sua pergunta")
    
    # Em app.py, localize o bloco `with st.expander(...)` e substitua seu conte√∫do por este:

    with st.expander("‚ÑπÔ∏è **Guia do Usu√°rio: Como Extrair o M√°ximo do Agente**", expanded=False): # `expanded=False` √© uma boa pr√°tica para n√£o poluir a tela inicial
        st.markdown("""
        Este agente foi projetado para atuar como um consultor especialista em Planos de Incentivo de Longo Prazo (ILP), analisando uma base de dados de documentos p√∫blicos da CVM. Para obter os melhores resultados, formule perguntas que explorem suas principais capacidades.
        """)

        st.subheader("1. Perguntas de Listagem (Quem tem?) üéØ")
        st.info("""
        Use estas perguntas para identificar e listar empresas que adotam uma pr√°tica espec√≠fica. Ideal para mapeamento de mercado.
        """)
        st.markdown("**Exemplos:**")
        st.code("""- Liste as empresas que pagam dividendos ou JCP durante o per√≠odo de car√™ncia (vesting).
        - Quais companhias possuem cl√°usulas de Malus ou Clawback?
        - Gere uma lista de empresas que oferecem planos com contrapartida do empregador (Matching/Coinvestimento).
        - Quais organiza√ß√µes mencionam explicitamente o Comit√™ de Remunera√ß√£o como √≥rg√£o aprovador dos planos?""")

        st.subheader("2. An√°lise Estat√≠stica (Qual a m√©dia?) üìà")
        st.info("""
        Pergunte por m√©dias, medianas e outros dados estat√≠sticos para entender os n√∫meros por tr√°s das pr√°ticas de mercado e fazer benchmarks.
        """)
        st.markdown("**Exemplos:**")
        st.code("""- Qual o per√≠odo m√©dio de vesting (em anos) entre as empresas analisadas?
        - Qual a dilui√ß√£o m√°xima m√©dia (% do capital social) que os planos costumam aprovar?
        - Apresente as estat√≠sticas do desconto no pre√ßo de exerc√≠cio (m√≠nimo, m√©dia, m√°ximo).
        - Qual o prazo de lock-up (restri√ß√£o de venda) mais comum ap√≥s o vesting das a√ß√µes?""")

        st.subheader("3. Padr√µes de Mercado (Como √© o normal?) üó∫Ô∏è")
        st.info("""
        Fa√ßa perguntas abertas para que o agente analise diversos planos e descreva os padr√µes e as abordagens mais comuns para um determinado t√≥pico.
        """)
        st.markdown("**Exemplos:**")
        st.code("""- Analise os modelos t√≠picos de planos de A√ß√µes Restritas (RSU), o tipo mais comum no mercado.
        - Al√©m do TSR, quais s√£o as metas de performance (ESG, Financeiras) mais utilizadas pelas empresas?
        - Descreva os padr√µes de tratamento para condi√ß√µes de sa√≠da (Good Leaver vs. Bad Leaver) nos planos.
        - Quais as abordagens mais comuns para o tratamento de dividendos em a√ß√µes ainda n√£o investidas?""")

        st.subheader("4. An√°lise Profunda e Comparativa (Me explique em detalhes) üß†")
        st.info("""
        Use o poder do RAG para pedir an√°lises detalhadas sobre uma ou mais empresas, comparando regras e estruturas espec√≠ficas.
        """)
        st.markdown("**Exemplos:**")
        st.code("""- Como o plano da Vale trata a acelera√ß√£o de vesting em caso de mudan√ßa de controle?
        - Compare as cl√°usulas de Malus/Clawback da Vale com as do Ita√∫.
        - Descreva em detalhes o plano de Op√ß√µes de Compra da Localiza, incluindo prazos, condi√ß√µes e forma de liquida√ß√£o.
        - Descreva o Item 8.4 da M.dias Braco.
        - Quais as diferen√ßas na elegibilidade de participantes entre os planos da Magazine Luiza e da Lojas Renner?""")


        st.subheader("‚ùó Conhecendo as Limita√ß√µes")
        st.warning("""
        - **Fonte dos Dados:** Minha an√°lise se baseia em documentos p√∫blicos da CVM com data de corte 31/07/2025. N√£o tenho acesso a informa√ß√µes em tempo real ou privadas.
        - **Identifica√ß√£o de Nomes:** Para an√°lises profundas, preciso que o nome da empresa seja claro e reconhec√≠vel. Se o nome for amb√≠guo ou n√£o estiver na minha base, posso n√£o encontrar os detalhes.
        - **Escopo:** Sou altamente especializado em Incentivos de Longo Prazo. Perguntas fora deste dom√≠nio podem n√£o ter respostas adequadas.
        """)

    user_query = st.text_area("Sua pergunta:", height=100, placeholder="Ex: Quais s√£o os modelos t√≠picos de vesting? ou Como funciona o plano da Vale?")
    
    if st.button("üîç Analisar", type="primary", use_container_width=True):
        if not user_query.strip():
            st.warning("‚ö†Ô∏è Por favor, digite uma pergunta.")
            st.stop()
        active_filters = {}
        if selected_setor != "Todos":
            active_filters['setor'] = selected_setor.lower()
        if selected_controle != "Todos":
            # A chave 'controle_acionario' deve ser exatamente como nos metadados dos chunks.
            active_filters['controle_acionario'] = selected_controle.lower()
        if active_filters:
            # Formata o dicion√°rio para uma exibi√ß√£o amig√°vel.
            filter_text_parts = []
            if 'setor' in active_filters:
                filter_text_parts.append(f"**Setor**: {active_filters['setor'].capitalize()}")
            if 'controle_acionario' in active_filters:
                filter_text_parts.append(f"**Controle**: {active_filters['controle_acionario'].capitalize()}")

            filter_text = " e ".join(filter_text_parts)
            st.info(f"üîé An√°lise sendo executada com os seguintes filtros: {filter_text}")

        st.markdown("---")
        st.subheader("üìã Resultado da An√°lise")
                # --- IN√çCIO DA NOVA L√ìGICA DE ROTEAMENTO H√çBRIDO ---
        
        intent = None
        query_lower = user_query.lower()
        
        # 1. Camada de Regras: Verifica palavras-chave quantitativas √≥bvias primeiro.
        quantitative_keywords = [
            'liste', 'quais empresas', 'quais companhias', 'quantas', 'm√©dia', 
            'mediana', 'estat√≠sticas', 'mais comuns', 'preval√™ncia', 'contagem'
        ]
        
        if any(keyword in query_lower for keyword in quantitative_keywords):
            intent = "quantitativa"
            logger.info("Inten√ß√£o 'quantitativa' detectada por regras de palavras-chave.")
        
        # 2. Camada de LLM: Se nenhuma regra correspondeu, consulta o LLM.
        if intent is None:
            with st.spinner("Analisando a inten√ß√£o da sua pergunta..."):
                intent = get_query_intent_with_llm(user_query)

        # --- FIM DA NOVA L√ìGICA DE ROTEAMENTO H√çBRIDO ---

        if intent == "quantitativa":
            query_lower = user_query.lower()
            listing_keywords = ["quais empresas", "liste as empresas", "quais companhias"]
            thematic_keywords = ["modelos t√≠picos", "padr√µes comuns", "analise os planos", "formas mais comuns"]
                # --- IN√çCIO DA L√ìGICA CORRIGIDA E FINAL ---
            
            # 1. Usa a nova fun√ß√£o para criar o mapa hier√°rquico
            alias_map = create_hierarchical_alias_map(DICIONARIO_UNIFICADO_HIERARQUICO)
            found_topics = set()
            
            # 2. Itera nos aliases para encontrar os t√≥picos mencionados na query
            for alias in sorted(alias_map.keys(), key=len, reverse=True):
                if re.search(r'\b' + re.escape(alias) + r'\b', query_lower):
                    full_path = alias_map[alias]
                    topic_leaf = full_path.split(',')[-1].replace('_', ' ')
                    found_topics.add(topic_leaf)
            
            topics_to_search = list(found_topics)
            # Remove palavras-chave gen√©ricas da lista de t√≥picos
            topics_to_search = [t for t in topics_to_search if t.lower() not in listing_keywords and t.lower() not in thematic_keywords]

            # --- FIM DA L√ìGICA CORRIGIDA E FINAL ---

            # Rota 1: An√°lise Tem√°tica
            if any(keyword in query_lower for keyword in thematic_keywords) and topics_to_search:
                primary_topic = topics_to_search[0]
                with st.spinner(f"Iniciando an√°lise tem√°tica... Este processo √© detalhado e pode levar alguns minutos."):
                    st.write(f"**T√≥pico identificado para an√°lise tem√°tica:** `{topics_to_search}`")
                    final_report = analyze_topic_thematically(
                        topic=topics_to_search, query=user_query, artifacts=artifacts, model=embedding_model, kb=DICIONARIO_UNIFICADO_HIERARQUICO,
                        execute_dynamic_plan_func=execute_dynamic_plan, get_final_unified_answer_func=get_final_unified_answer,filters=active_filters,
                        company_catalog_rich=st.session_state.company_catalog_rich, company_lookup_map=st.session_state.company_lookup_map,
                    )
                    st.markdown(final_report)

            # Rota 2: Listagem de Empresas
            elif any(keyword in query_lower for keyword in listing_keywords) and topics_to_search:
                with st.spinner(f"Usando ferramentas para encontrar empresas..."):
                    st.write(f"**T√≥picos identificados para busca:** `{', '.join(topics_to_search)}`")
        
                    all_found_companies = set()
        
                    # CORRE√á√ÉO: Itera sobre a lista e chama a ferramenta para CADA t√≥pico.
                    for topic_item in topics_to_search:
                        companies = find_companies_by_topic(
                            topic=topic_item,  # Passa um √∫nico t√≥pico (string)
                            artifacts=artifacts, 
                            model=embedding_model, 
                            kb=DICIONARIO_UNIFICADO_HIERARQUICO,
                            filters=active_filters                            
                        )
                        all_found_companies.update(companies)

                    if all_found_companies:
                        sorted_companies = sorted(list(all_found_companies))
                        final_answer = f"#### Foram encontradas {len(sorted_companies)} empresas para os t√≥picos relacionados:\n"
                        final_answer += "\n".join([f"- {company}" for company in sorted_companies])
                    else:
                        final_answer = "Nenhuma empresa encontrada nos documentos para os t√≥picos identificados."
                
                st.markdown(final_answer)
                     # --- IN√çCIO DA NOVA ROTA 2.5 ---
            # Rota 2.5: Listagem de Empresas APENAS POR FILTRO
            elif any(keyword in query_lower for keyword in listing_keywords) and active_filters and not topics_to_search:
                with st.spinner("Listando empresas com base nos filtros selecionados..."):
                    st.write("Nenhum t√≥pico t√©cnico identificado. Listando todas as empresas que correspondem aos filtros.")
                    
                    companies_from_filter = set()
                    # Itera em todos os documentos para encontrar empresas que correspondem ao filtro
                    for artifact_data in artifacts.values():
        # Acessa diretamente a lista de chunks, que cont√©m os metadados.
                        list_of_chunks = artifact_data.get('chunks', [])

                        if not isinstance(list_of_chunks, list):
                            continue

                        for metadata in list_of_chunks:
                            # --- IN√çCIO DA CORRE√á√ÉO ---
                            setor_metadata = metadata.get('setor', '')
                            controle_metadata = metadata.get('controle_acionario', '')

                            setor_match = (not active_filters.get('setor') or 
                                           (isinstance(setor_metadata, str) and setor_metadata.lower() == active_filters['setor']))
                        
                            controle_match = (not active_filters.get('controle_acionario') or 
                                              (isinstance(controle_metadata, str) and controle_metadata.lower() == active_filters['controle_acionario']))
                            # --- FIM DA CORRE√á√ÉO ---
                            if setor_match and controle_match:
                                company_name = metadata.get('company_name')
                                if company_name:
                                    companies_from_filter.add(company_name)
                    
                    if companies_from_filter:
                        sorted_companies = sorted(list(companies_from_filter))
                        final_answer = f"#### Foram encontradas {len(sorted_companies)} empresas para os filtros selecionados:\n"
                        final_answer += "\n".join([f"- {company}" for company in sorted_companies])
                    else:
                        final_answer = "Nenhuma empresa foi encontrada para a combina√ß√£o de filtros selecionada."
                    
                    st.markdown(final_answer)

            # Rota 3: Fallback para o AnalyticalEngine
            else:
                st.info("Inten√ß√£o quantitativa detectada. Usando o motor de an√°lise r√°pida...")
                with st.spinner("Executando an√°lise quantitativa r√°pida..."):
                    report_text, data_result = engine.answer_query(user_query, filters=active_filters)
                    if report_text: st.markdown(report_text)
                    if data_result is not None:
                        if isinstance(data_result, pd.DataFrame):
                            if not data_result.empty: st.dataframe(data_result, use_container_width=True, hide_index=True)
                        elif isinstance(data_result, dict):
                            for df_name, df_content in data_result.items():
                                if df_content is not None and not df_content.empty:
                                    st.markdown(f"#### {df_name}")
                                    st.dataframe(df_content, use_container_width=True, hide_index=True)
                    else: 
                        st.info("Nenhuma an√°lise tabular foi gerada para a sua pergunta ou dados insuficientes.")
        
        else: # intent == 'qualitativa'
            final_answer, sources = handle_rag_query(
                user_query, 
                artifacts, 
                embedding_model, 
                cross_encoder_model, 
                kb=DICIONARIO_UNIFICADO_HIERARQUICO,
                company_catalog_rich=st.session_state.company_catalog_rich, 
                company_lookup_map=st.session_state.company_lookup_map, 
                summary_data=summary_data,
                filters=active_filters,
                prioritize_recency=prioritize_recency
            )
            st.markdown(final_answer)
            
            if sources:
                with st.expander(f"üìö Documentos consultados ({len(sources)})", expanded=True):
                    st.caption("Nota: Links diretos para a CVM podem falhar. Use a busca no portal com o protocolo como plano B.")
        
        # --- BLOCO CORRIGIDO ---
                    for src in sorted(sources, key=lambda x: x.get('company_name', '')):
                        company_name = src.get('company_name', 'N/A')
                        doc_date = src.get('document_date', 'N/A') 
                        doc_type_raw = src.get('doc_type', '')
                        url = src.get('source_url', '')

                        if doc_type_raw == 'outros_documentos':
                            display_doc_type = 'Plano de Remunera√ß√£o'
                        else:
                            display_doc_type = doc_type_raw.replace('_', ' ')
            
                        display_text = f"{company_name} - {display_doc_type} - (Data: **{doc_date}**)"
            
                        # A l√≥gica de exibi√ß√£o agora est√° corretamente separada por tipo de documento
                        if "frmExibirArquivoIPEExterno" in url:
                            # O protocolo S√ì √© definido e usado dentro deste bloco
                            protocolo_match = re.search(r'NumeroProtocoloEntrega=(\d+)', url)
                            protocolo = protocolo_match.group(1) if protocolo_match else "N/A"
                            st.markdown(f"**{display_text}** (Protocolo: **{protocolo}**)")
                            st.markdown(f"‚Ü≥ [Link Direto para Plano de ILP]({url}) ", unsafe_allow_html=True)
            
                        elif "frmExibirArquivoFRE" in url:
                            # Este bloco n√£o usa a vari√°vel 'protocolo'
                            st.markdown(f"**{display_text}**")
                            st.markdown(f"‚Ü≥ [Link Direto para Formul√°rio de Refer√™ncia]({url})", unsafe_allow_html=True)
            
                        else:
                            # Este bloco tamb√©m n√£o usa a vari√°vel 'protocolo'
                            st.markdown(f"**{display_text}**: [Link]({url})")


if __name__ == "__main__":
    main()
